{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":223,"status":"ok","timestamp":1717069023236,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"lbbG1RspOoXC","outputId":"0fba4865-c6c2-4620-dfdb-340124a1d0d3"},"outputs":[],"source":["import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.optim import Adam\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","import matplotlib.pyplot as plt\n","import time\n","from model import MambaFull, generate_data, seq2seq_generate_tour, compute_tour_length\n","from datetime import datetime\n","\n","# Define model parameters and hyperparameters\n","class DotDict(dict):\n","    def __init__(self, **kwds):\n","        self.update(kwds)\n","        self.__dict__ = self\n","\n","args=DotDict() \n","\n","#Args for the model\n","args.bsz=600\n","args.d_model = 100\n","args.coord_dim = 2\n","args.nb_layers = 3\n","args.mlp_cls = nn.Identity #nn.Linear #TODO\n","args.city_count = 10\n","args.deterministic = False #used for sampling from the model\n","args.fourier_scale = 10 #If set as None a standard Linear map is used else a gaussian fourier feature mapping is used\n","\n","#Args for the training\n","args.nb_epochs=50\n","args.test_size=2000\n","args.nb_batch_per_epoch=10\n","args.save_loc = 'mamba/checkpoints/embed/fourier10_emb'\n","args.test_data_loc=f'mamba/data/start_2/test_rand_{args.test_size}_{args.city_count}_{args.coord_dim}.pt'\n","#0 => data will not be recycled and each step new data is generated, however this will make the gpu spend most of the time loading data. Recommeded val is 100\n","args.recycle_data=0"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Parameter: norm_f.weight, Size: torch.Size([100])\n","Parameter: norm_f.bias, Size: torch.Size([100])\n","Parameter: layers.0.norm.weight, Size: torch.Size([100])\n","Parameter: layers.0.norm.bias, Size: torch.Size([100])\n","Parameter: layers.0.mixer.A_log, Size: torch.Size([200, 100])\n","Parameter: layers.0.mixer.D, Size: torch.Size([200])\n","Parameter: layers.0.mixer.in_proj.weight, Size: torch.Size([400, 100])\n","Parameter: layers.0.mixer.conv1d.weight, Size: torch.Size([200, 1, 4])\n","Parameter: layers.0.mixer.conv1d.bias, Size: torch.Size([200])\n","Parameter: layers.0.mixer.x_proj.weight, Size: torch.Size([207, 200])\n","Parameter: layers.0.mixer.dt_proj.weight, Size: torch.Size([200, 7])\n","Parameter: layers.0.mixer.dt_proj.bias, Size: torch.Size([200])\n","Parameter: layers.0.mixer.out_proj.weight, Size: torch.Size([100, 200])\n","Parameter: layers.1.norm.weight, Size: torch.Size([100])\n","Parameter: layers.1.norm.bias, Size: torch.Size([100])\n","Parameter: layers.1.mixer.A_log, Size: torch.Size([200, 100])\n","Parameter: layers.1.mixer.D, Size: torch.Size([200])\n","Parameter: layers.1.mixer.in_proj.weight, Size: torch.Size([400, 100])\n","Parameter: layers.1.mixer.conv1d.weight, Size: torch.Size([200, 1, 4])\n","Parameter: layers.1.mixer.conv1d.bias, Size: torch.Size([200])\n","Parameter: layers.1.mixer.x_proj.weight, Size: torch.Size([207, 200])\n","Parameter: layers.1.mixer.dt_proj.weight, Size: torch.Size([200, 7])\n","Parameter: layers.1.mixer.dt_proj.bias, Size: torch.Size([200])\n","Parameter: layers.1.mixer.out_proj.weight, Size: torch.Size([100, 200])\n","Parameter: layers.2.norm.weight, Size: torch.Size([100])\n","Parameter: layers.2.norm.bias, Size: torch.Size([100])\n","Parameter: layers.2.mixer.A_log, Size: torch.Size([200, 100])\n","Parameter: layers.2.mixer.D, Size: torch.Size([200])\n","Parameter: layers.2.mixer.in_proj.weight, Size: torch.Size([400, 100])\n","Parameter: layers.2.mixer.conv1d.weight, Size: torch.Size([200, 1, 4])\n","Parameter: layers.2.mixer.conv1d.bias, Size: torch.Size([200])\n","Parameter: layers.2.mixer.x_proj.weight, Size: torch.Size([207, 200])\n","Parameter: layers.2.mixer.dt_proj.weight, Size: torch.Size([200, 7])\n","Parameter: layers.2.mixer.dt_proj.bias, Size: torch.Size([200])\n","Parameter: layers.2.mixer.out_proj.weight, Size: torch.Size([100, 200])\n","Parameter: output_head.weight, Size: torch.Size([10, 100])\n","Total number of parameters: 374400\n"]}],"source":["\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","#model which will be train and baseline as in the REINFORCE algorithm. \n","model_train = MambaFull(args.d_model, args.city_count, args.nb_layers, args.coord_dim, args.mlp_cls, fourier_scale = args.fourier_scale).to(device)\n","model_baseline = MambaFull(args.d_model, args.city_count, args.nb_layers, args.coord_dim, args.mlp_cls, fourier_scale = args.fourier_scale).to(device)\n","\n","\n","checkpoint=None\n","#checkpoint = torch.load('mamba/checkpoints/best_checkpoint_3000_6.pt') #Highlight out if no chekpoint is available\n","if checkpoint:\n","    model_train.load_state_dict(checkpoint['model_state_dict'])\n","    tot_time_ckpt = checkpoint['tot_time']\n","    start_epoch = checkpoint['epoch']\n","    mean_tour_length_list = checkpoint['mean_tour_length_list']\n","    mean_tour_length_best = checkpoint['mean_tour_length_list'][-1]\n","else:\n","    tot_time_ckpt, start_epoch = 0,0\n","    mean_tour_length_list = [] \n","    mean_tour_length_best = float('inf') \n","\n","model_baseline.load_state_dict(model_train.state_dict())\n","model_baseline.eval()\n","for name, param in model_train.named_parameters():\n","    print(f\"Parameter: {name}, Size: {param.size()}\")\n","total_params = sum(p.numel() for p in model_train.parameters())\n","print(f\"Total number of parameters: {total_params}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":8308710,"status":"ok","timestamp":1717077410267,"user":{"displayName":"","userId":""},"user_tz":-60},"id":"w5jGHXaBOoXM","outputId":"11bd84fd-f86b-412e-b546-f158d22564f6"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2000, 11, 2])\n","[torch.Size([600, 11, 2]), torch.Size([600, 11, 2]), torch.Size([600, 11, 2]), torch.Size([200, 11, 2])]\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e600673df2094cac92e7de6d199eeaec","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/50 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Epoch 0, test tour length train: 5.2020158767700195, test tour length baseline: 5.2004241943359375, time one epoch: 19.47865080833435, time tot: 19.48715090751648\n","Epoch 1, test tour length train: 5.199448108673096, test tour length baseline: 5.2004241943359375, time one epoch: 14.828474044799805, time tot: 36.825860261917114\n","Epoch 2, test tour length train: 5.192124843597412, test tour length baseline: 5.199448108673096, time one epoch: 15.000221252441406, time tot: 54.36800003051758\n","Epoch 3, test tour length train: 5.199132919311523, test tour length baseline: 5.192124843597412, time one epoch: 15.116082191467285, time tot: 72.05290722846985\n","Epoch 4, test tour length train: 5.196896553039551, test tour length baseline: 5.192124843597412, time one epoch: 15.241295576095581, time tot: 89.85929131507874\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[3], line 39\u001b[0m\n\u001b[1;32m     37\u001b[0m     loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean( (L_train \u001b[38;5;241m-\u001b[39m L_baseline)\u001b[38;5;241m*\u001b[39m sumLogProbOfActions )\n\u001b[1;32m     38\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     42\u001b[0m time_one_epoch \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;241m-\u001b[39mstart\n","File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["loss_fn = nn.CrossEntropyLoss()\n","optimizer = Adam(model_train.parameters(), lr=1e-4)\n","\n","test_data = torch.load(args.test_data_loc).to(device)\n","test_data_batches = torch.split(test_data, args.bsz)\n","\n","print(test_data.shape)\n","print([x.shape for x in test_data_batches])\n","\n","start_training_time = time.time()\n","now = datetime.now()\n","date_time = now.strftime(\"%d%m_%H%M\")\n","\n","# Training loop\n","for epoch in tqdm(range(start_epoch,args.nb_epochs)):\n","    model_train.train()\n","    i= 0 # Tracks the number of steps before we generate new data\n","    start = time.time()\n","    for step in range(args.nb_batch_per_epoch):\n","\n","        if i == 0:\n","            #Inputs will have size (bsz, seq_len, coord_dim)\n","            inputs = generate_data(device, args.bsz, args.city_count, args.coord_dim)\n","            i=args.recycle_data\n","        else: i-=1\n","\n","        # list that will contain Long tensors of shape (bsz,) that gives the idx of the cities chosen at time t\n","        tours_train, sumLogProbOfActions = seq2seq_generate_tour(device,model_train,inputs,args.deterministic)\n","        tours_baseline, _ = seq2seq_generate_tour(device,model_baseline,inputs,args.deterministic)\n","        #get the length of the tours\n","        with torch.no_grad():\n","            L_train = compute_tour_length(inputs, tours_train)\n","            L_baseline = compute_tour_length(inputs, tours_baseline)\n","        #print(f\"L_train requires_grad: {L_train.requires_grad}\")\n","\n","        # backprop     \n","        loss = torch.mean( (L_train - L_baseline)* sumLogProbOfActions )\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","        \n","    time_one_epoch = time.time()-start\n","    time_tot = time.time()-start_training_time + tot_time_ckpt\n","\n","    ###################\n","    # Evaluate train model and baseline\n","    ###################\n","    model_train.eval()\n","    L_train_total = 0\n","    L_baseline_total = 0\n","    \n","    # Compute tour for model and baseline for test data, making it sure its split to not overload the gpu\n","    for test_data_batch in test_data_batches:\n","        tour_train, _ = seq2seq_generate_tour(device, model_train, test_data_batch, deterministic=True)\n","        tour_baseline, _ = seq2seq_generate_tour(device, model_baseline, test_data_batch, deterministic=True)\n","\n","        # Get the lengths of the tours and add to the accumulators\n","        L_train_total += compute_tour_length(test_data_batch, tour_train).sum()\n","        L_baseline_total += compute_tour_length(test_data_batch, tour_baseline).sum()\n","\n","    # Compute the average tour lengths\n","    L_train = L_train_total / args.test_size\n","    L_baseline = L_baseline_total / args.test_size\n","\n","    print(f'Epoch {epoch}, test tour length train: {L_train}, test tour length baseline: {L_baseline}, time one epoch: {time_one_epoch}, time tot: {time_tot}')\n","\n","    mean_tour_length_list.append(L_train)\n","    # evaluate train model and baseline and update if train model is better\n","    if L_train < L_baseline:\n","        model_baseline.load_state_dict( model_train.state_dict() )\n","\n","    # Save checkpoint every 10,000 epochs\n","    if L_train < mean_tour_length_best:\n","        mean_tour_length_best = L_train\n","\n","        # Append to filename\n","        filename = f\"file_{date_time}.pt\"\n","        checkpoint = {\n","            'epoch': epoch,\n","            'model_state_dict': model_train.state_dict(),\n","            'optimizer_state_dict': optimizer.state_dict(),\n","            'mean_tour_length_list': mean_tour_length_list,\n","            'args': args,\n","            'time_tot': time_tot\n","        }\n","        torch.save(checkpoint, f'{args.save_loc}_{date_time}.pt' )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["checkpoint = torch.load('mamba/best_checkpoint.pt')\n","print(checkpoint.keys())\n","checkpoint2 = torch.load('mamba/best_checkpoint_3000_6.pt')\n","#model_train.load_state_dict(checkpoint['model_state_dict'])\n","#model_train.eval()\n","mean_tour_length_list = [tensor.cpu().numpy() for tensor in checkpoint['mean_tour_length_list']]\n","mean_tour_length_list2 = [tensor.cpu().numpy() for tensor in checkpoint2['mean_tour_length_list']]\n","print(checkpoint['epoch'])\n","plt.plot(mean_tour_length_list)\n","plt.plot(mean_tour_length_list2)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9xbxPNIOoXN"},"outputs":[],"source":["from model import plot_tsp\n","x = generate_data(device, 1, args.city_count, args.coord_dim)\n","tour, _ = seq2seq_generate_tour(device,model_train,x,deterministic=True)\n","plot_tsp(x,tour)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"https://github.com/Fisher2107/mamba-minimal/blob/master/selective_copy.ipynb","timestamp":1717088414324}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.10"}},"nbformat":4,"nbformat_minor":0}
